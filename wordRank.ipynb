{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Rizzlite Word Ranking**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Preprocess Manually Ranked Sentences**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/skylerestavillo/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import random\n",
    "import csv\n",
    "import re\n",
    "import contractions\n",
    "from random import uniform\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create personalized list of stop words, which will be set to neutral score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create personalized list of stop words\n",
    "stop_words = [ \"of\", \"should\", \"not\", \"are\", \"i\", \"her\", \"here\", \"their\", \"again\", \"can\", \"above\", \"these\", \"will\", \"all\", \n",
    "\"them\", \"has\", \"she\", \"him\", \"his\", \"itself\", \"it\", \"is\", \"out\", \"had\", \"he\", \"hers\", \"because\", \"were\", \"than\", \"not\",\n",
    "\"and\", \"under\", \"during\", \"into\", \"am\", \"have\", \"yours\", \"a\", \"some\", \"have\", \"has\", \"ours\", \"or\", \"by\", \"our\", \"at\",\n",
    "\"on\", \"same\", \"you\", \"does\", \"was\", \"did\", \"theirs\", \"herself\", \"himself\",\n",
    "\"does\", \"they\", \"up\", \"between\", \"such\", \"both\", \"nor\", \"having\", \"are\", \"an\", \"no\", \"ain't\", \"as\", \"before\", \"with\",\n",
    "\"have\", \"other\", \"she\", \"in\", \"for\", \"themselves\", \"do\", \"the\", \"against\", \"so\", \"ourselves\", \"to\", \"did\",\n",
    "\"doing\", \"each\", \"been\", \"has\", \"after\", \"off\", \"but\", \"through\", \"it\", \"this\", \"own\",\n",
    "\"any\", \"now\", \"if\", \"while\", \"down\", \"only\", \"being\", \"my\", \"had\", \"we\", \"then\", \"until\", \"from\",\n",
    "\"further\", \"there\", \"that\", \"went\", \"those\"]\n",
    "\n",
    "word_scores = {}\n",
    "\n",
    "for word in set(stop_words):\n",
    "    word_scores[word] = 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function to preprocess sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to preprocess each sentence\n",
    "def preprocess_sentence(sentence):\n",
    "    # Convert the input to a string and then to lowercase\n",
    "    sentence = str(sentence).lower()\n",
    "    \n",
    "    # Remove words containing numbers from the sentence\n",
    "    sentence = re.sub(r'\\b\\w*\\d\\w*\\b', '', sentence)\n",
    "    \n",
    "    # Break apart contractions using the contractions library\n",
    "    sentence = contractions.fix(sentence)\n",
    "    \n",
    "    # Remove all non-alphabetic characters from the sentence\n",
    "    sentence = re.sub(r'[^a-zA-Z\\s]', '', sentence)\n",
    "    \n",
    "    # Ensure the sentence is returned as a string of words\n",
    "    sentence = ' '.join(sentence.split())\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read csv file, preprocess, and set scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id language                                   Sentence  Score Unnamed: 4\n",
      "0  0.0      eng                       let us try something    3.5        NaN\n",
      "1  1.0      eng                      i have to go to sleep    3.7        NaN\n",
      "2  2.0      eng  today is june and it is muiriels birthday    4.2        NaN\n",
      "3  3.0      eng                             muiriel is now    4.8        NaN\n",
      "4  4.0      eng                    the password is muiriel    4.8        NaN\n"
     ]
    }
   ],
   "source": [
    "# Read in the csv file\n",
    "df = pd.read_csv('SentenceCorpus.csv')\n",
    "\n",
    "\n",
    "# Preprocess each sentence in the 'Sentence' column\n",
    "df['Sentence'] = df['Sentence'].apply(preprocess_sentence)\n",
    "\n",
    "# Print the updated dataframe\n",
    "print(df.head())\n",
    "\n",
    "# Define a function to tokenize a sentence and return a list of words\n",
    "def tokenize(sentence):\n",
    "    return sentence.split()\n",
    "\n",
    "# Update the word_scores dictionary with words and their scores\n",
    "for index, row in df.iterrows():\n",
    "    sentence = row['Sentence']\n",
    "    score = row['Score']\n",
    "    words = tokenize(sentence)\n",
    "\n",
    "    # If its a new non stop word, add it to the dictionary\n",
    "    # If we've seen it before, append the new score to the list of scores\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            if word not in word_scores:\n",
    "                word_scores[word] = [score]\n",
    "            else:\n",
    "                word_scores[word].append(score)\n",
    "\n",
    "# Calculate the average score for each word\n",
    "word_final_scores = {}\n",
    "for word, scores in word_scores.items():\n",
    "    if isinstance(scores, list):\n",
    "        word_final_scores[word] = sum(scores) / len(scores)\n",
    "    else:\n",
    "        word_final_scores[word] = scores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test our dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in the dictionary: 2617\n",
      "handsome: 5.0\n",
      "won: 4.15\n",
      "analysis: 2.5\n",
      "travel: 2.8666666666666667\n",
      "infirmary: 3.8\n",
      "arrived: 3.85\n",
      "here: 3\n",
      "criticism: 5.0\n",
      "letter: 1.7333333333333334\n",
      "glasses: 3.5666666666666664\n"
     ]
    }
   ],
   "source": [
    "# Print the count of all words in the dictionary\n",
    "print(f\"Total words in the dictionary: {len(word_final_scores)}\")\n",
    "\n",
    "# Print 10 random words in the dictionary with their associated scores\n",
    "random_words = random.sample(list(word_final_scores.items()), 10)\n",
    "for word, score in random_words:\n",
    "    print(f\"{word}: {score}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define API Request Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"YOUR KEY HERE\"\n",
    "\n",
    "# Define synonym API request\n",
    "def get_synonyms(word):\n",
    "    url = f\"https://wordsapiv1.p.rapidapi.com/words/{word}/synonyms\"\n",
    "    headers = {\n",
    "        \"content-type\": \"application/octet-stream\",\n",
    "        \"X-RapidAPI-Key\": API_KEY,\n",
    "        \"X-RapidAPI-Host\": \"wordsapiv1.p.rapidapi.com\"\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    return response.json().get('synonyms', [])\n",
    "\n",
    "\n",
    "# Definition definition API request\n",
    "def get_definition(word):\n",
    "    url = f\"https://wordsapiv1.p.rapidapi.com/words/{word}/definitions\"\n",
    "    headers = {\n",
    "        \"content-type\": \"application/octet-stream\",\n",
    "        \"X-RapidAPI-Key\": API_KEY,\n",
    "        \"X-RapidAPI-Host\": \"wordsapiv1.p.rapidapi.com\"\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    return response.json().get('definitions', [])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grow Dataset with Synonyms and Definitions From API Calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import model\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "glove_model = api.load('glove-twitter-200')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to save progress into dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_word_final_scores_to_csv():\n",
    "    with open('word_scores.csv', 'w', newline='') as csvfile:\n",
    "        fieldnames = ['Word', 'Score']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for word, score in word_final_scores.items():\n",
    "            writer.writerow({'Word': word, 'Score': score})\n",
    "    print(\"Progress saved to word_scores.csv\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call Function to Save Progress Along the Way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_word_final_scores_to_csv()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define/Redefine global variables and re-read data into them from previous iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "called_words = set()\n",
    "used_words = set()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the read function only if you've built the necessary csv files (called below in random_k function)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_words.clear()\n",
    "called_words.clear()\n",
    "\n",
    "# Read used_words back into the used_words set\n",
    "with open(\"used_words.csv\", \"r\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    csv_reader = csv.reader(csvfile)\n",
    "    next(csv_reader)  # Skip the header\n",
    "    used_words = {row[0] for row in csv_reader}\n",
    "\n",
    "# Read called_words back into the called_words set\n",
    "with open(\"called_words.csv\", \"r\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    csv_reader = csv.reader(csvfile)\n",
    "    next(csv_reader)  # Skip the header\n",
    "    called_words = {row[0] for row in csv_reader}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write used_words to CSV file\n",
    "with open(\"used_words.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    csv_writer.writerow([\"Word\"])\n",
    "    for word in used_words:\n",
    "        csv_writer.writerow([word])\n",
    "\n",
    "# Write called_words to CSV file\n",
    "with open(\"called_words.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    csv_writer.writerow([\"Word\"])\n",
    "    for word in called_words:\n",
    "        csv_writer.writerow([word])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Re-read values into our dictionary obtained from previous iterations (if created)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_final_scores.clear()\n",
    "\n",
    "# Read word_scores.csv file\n",
    "df = pd.read_csv(\"word_scores.csv\")\n",
    "\n",
    "# Preprocess the data\n",
    "df[\"Word\"] = df[\"Word\"].astype(str)\n",
    "df = df[df[\"Word\"].apply(lambda x: not any(char.isdigit() for char in x))]\n",
    "df[\"Word\"] = df[\"Word\"].apply(lambda x: re.sub(r'[^ \\w+]', '', x))  # Remove non-alphanumeric characters except spaces\n",
    "df = df[df[\"Word\"] != \"\"]  # Remove rows with empty strings\n",
    "df[\"Word\"] = df[\"Word\"].apply(lambda x: x.lower())  # Convert the word to lowercase\n",
    "\n",
    "\n",
    "\n",
    "# Add words and scores to the word_final_scores dictionary\n",
    "for index, row in df.iterrows():\n",
    "    word_final_scores[row[\"Word\"]] = row[\"Score\"]\n",
    "\n",
    "\n",
    "# Add words and scores to the word_scores dictionary!!\n",
    "# !! This is the dictionary that is clean and will generate random words\n",
    "for index, row in df.iterrows():\n",
    "    word_scores[row[\"Word\"]] = row[\"Score\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to clean definition words and synonyms from API calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_word(word):\n",
    "    if not isinstance(word, str):\n",
    "        word = str(word)\n",
    "    if any(char.isdigit() for char in word):\n",
    "        return None\n",
    "    word = re.sub(r'[^ \\w+]', '', word)  # Remove non-alphanumeric characters except spaces\n",
    "    if word == \"\":\n",
    "        return None\n",
    "    word = word.lower()\n",
    "    return word"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Call the API Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_limit = 20000\n",
    "api_calls_made = 13923\n",
    "\n",
    "def k_nearest_neighbors(word, k=10, use_api = True, api_limit=20000):\n",
    "    global api_calls_made, called_words\n",
    "\n",
    "    # Use the Words API to find synonyms if the use_api flag is set to True and the API limit is not exceeded\n",
    "    if use_api and word not in called_words and api_limit > 0 and api_calls_made < api_limit:\n",
    "        # Add the word to the called_words set to prevent duplicate API calls\n",
    "        called_words.add(word)\n",
    "        api_calls_made += 1  # Increment the API calls counter\n",
    "\n",
    "        synonyms = get_synonyms(word)\n",
    "        # If the API returns synonyms, return the list of synonyms\n",
    "        for synonym in synonyms[:k]:\n",
    "            synonym = clean_word(synonym)\n",
    "            if synonym and synonym not in word_final_scores: # if synonym is not none and not in word_final_scores\n",
    "                print(f\"Getting definition for {synonym}\")\n",
    "                api_calls_made += 1  # Increment the API calls counter\n",
    "                # This may return more than 1 definition, so we need to iterate through each definition\n",
    "                definitions = get_definition(synonym)\n",
    "                definition_score = 0 \n",
    "                word_count = 0\n",
    "                new_words = set()  # Initialize a set to store new words found in the definition\n",
    "                for definition in definitions:\n",
    "                    # For words in the definition, check if they are in the word_final_scores dictionary\n",
    "                    for def_word in definition['definition'].split():\n",
    "                        def_word = clean_word(def_word)\n",
    "                        if def_word and def_word in word_final_scores: # if def_word is not none and in word_final_scores\n",
    "                            # If the word is in the dictionary, add the score to the definition score and increment the word count\n",
    "                            definition_score += word_final_scores[def_word]\n",
    "                            # Increment the word count\n",
    "                            word_count += 1\n",
    "                        else:\n",
    "                            definition_score += 3 # Increase by a neutral number if we this word is new\n",
    "                            word_count += 1\n",
    "                            new_words.add(def_word)  # Add the new word to the set for rapid scoring later\n",
    "\n",
    "                # If the definition has more words than 0, calculate the average definition score\n",
    "                if word_count > 0:\n",
    "                    average_definition_score = definition_score / word_count \n",
    "\n",
    "                    # If the definition score is slightly higher than OG word, rank synonym higher\n",
    "                    if average_definition_score > word_final_scores[word]:\n",
    "                        score_adjustment = uniform(0, 0.2) \n",
    "                        new_score = min(5, word_final_scores[word] + score_adjustment)\n",
    "                    # Else, rank the synonym slightly lower\n",
    "                    else:\n",
    "                        score_adjustment = uniform(-0.2, 0)\n",
    "                        new_score = max(1, word_final_scores[word] + score_adjustment)\n",
    "                    \n",
    "                    word_final_scores[synonym] = new_score\n",
    "                    print(f\"Adding word: {synonym} {new_score}\")  # Print the added word and its score\n",
    "\n",
    "                    # For newly encountered words form definition, give them a score close to the synonyms scores\n",
    "                    for new_word in new_words:\n",
    "                        adjusted_new_score = max(1, min(5, new_score + uniform(-0.2, 0.2)))\n",
    "                        word_final_scores[new_word] = adjusted_new_score\n",
    "                        print(f\"Adding word: {new_word} {adjusted_new_score}\")  # Print the added word and its score\n",
    "                # If the definition has no words/no definition returned, assign OG score to the synonym\n",
    "                else:\n",
    "                    word_final_scores[synonym] = word_final_scores[word]\n",
    "                    print(f\"Adding word: {synonym} {word_final_scores[synonym]}\")  # Print the added word and its score\n",
    "                    # Assign the synonym's score to each new word found in the definition\n",
    "                    # Should not happen often, but just in case\n",
    "                    for new_word in new_words:\n",
    "                        word_final_scores[new_word] = word_final_scores[word]\n",
    "                        print(f\"Adding word: {new_word} {word_final_scores[new_word]}\")  # Print the added word and its score\n",
    "    else:\n",
    "        # For a given word, find its first-level neighbors using the GloVe model\n",
    "        first_level_neighbors = glove_model.most_similar(positive=[word], topn=k)\n",
    "\n",
    "        for first_neighbor, _ in first_level_neighbors:\n",
    "            # Find their neighbors (second-level neighbors)\n",
    "            second_level_neighbors = glove_model.most_similar(positive=[first_neighbor], topn=k)\n",
    "            scored_second_level_neighbors = [n for n, _ in second_level_neighbors if n in word_final_scores]\n",
    "\n",
    "            # Calculate the average score of known second-level neighbors\n",
    "            if len(scored_second_level_neighbors) >= 1:\n",
    "                # If the first-level neighbor is not in the word_final_scores dictionary, add it. Otherwise, skip\n",
    "                if first_neighbor not in word_final_scores:\n",
    "                    avg_score = sum(word_final_scores[n] for n in scored_second_level_neighbors) / len(scored_second_level_neighbors)\n",
    "                    word_final_scores[first_neighbor] = avg_score\n",
    "                    print(f\"Adding word: {first_neighbor} {avg_score}\")\n",
    "\n",
    "            unknown_second_level_neighbors = []\n",
    "\n",
    "            # For each unknown second-level neighbor, add it to a list\n",
    "            for second_neighbor, _ in second_level_neighbors:\n",
    "                if second_neighbor not in word_final_scores:\n",
    "                    unknown_second_level_neighbors.append(second_neighbor)\n",
    "\n",
    "            # For each unknown second-level neighbor, find its neighbors (third-level neighbors)\n",
    "            for second_neighbor in unknown_second_level_neighbors:\n",
    "                third_level_neighbors = glove_model.most_similar(positive=[second_neighbor], topn=k)\n",
    "                scored_third_level_neighbors = [n for n, _ in third_level_neighbors if n in word_final_scores]\n",
    "\n",
    "                # Try to score the unknown second-level neighbor\n",
    "                if len(scored_third_level_neighbors) >= 1:\n",
    "                    # If the second-level neighbor is not in the word_final_scores dictionary, add it. Otherwise, skip\n",
    "                    if second_neighbor not in word_final_scores:\n",
    "                        avg_score = sum(word_final_scores[n] for n in scored_third_level_neighbors) / len(scored_third_level_neighbors)\n",
    "                        word_final_scores[second_neighbor] = avg_score\n",
    "                        print(f\"Adding word: {second_neighbor} {avg_score}\")\n",
    "\n",
    "                # Assign each unknown third-level neighbor a score equal to its respective second-level neighbor's score\n",
    "                for third_neighbor, _ in third_level_neighbors:\n",
    "                    if third_neighbor not in word_final_scores:\n",
    "                        # if we know the second neighbor's score, apply it with some noise\n",
    "                        if second_neighbor in word_final_scores:\n",
    "                            adjusted_score = max(1, min(5, word_final_scores[second_neighbor] + uniform(-0.15, 0.15)))\n",
    "                            word_final_scores[third_neighbor] = adjusted_score\n",
    "                            print(f\"Adding word: {third_neighbor} {adjusted_score}\")\n",
    "                        # if we don't know the second neighbor's score, apply the first neighbor's score with some noise\n",
    "                        else:\n",
    "                            adjusted_score = max(1, min(5, word_final_scores[first_neighbor] + uniform(-0.15, 0.15)))\n",
    "                            word_final_scores[third_neighbor] = adjusted_score\n",
    "                            print(f\"Adding word: {third_neighbor} {adjusted_score}\")\n",
    "\n",
    "\n",
    "    return api_calls_made  # Return the number of API calls made\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def random_word_k_nearest_neighbors():\n",
    "    global api_calls_made\n",
    "    save_interval = 50\n",
    "    iterations = 0\n",
    "\n",
    "    while True:\n",
    "        # Get the list of words found in our clean dictionary that is a non-stop word not in used_words\n",
    "        remaining_words = [word for word in word_scores.keys() if word not in stop_words and word not in used_words]\n",
    "\n",
    "        # Break the loop if there are no remaining words\n",
    "        if not remaining_words:\n",
    "            print(\"No remaining words\")\n",
    "            break\n",
    "\n",
    "        # Select a random non-stop word from the remaining_words list\n",
    "        random_word = random.choice(remaining_words)\n",
    "        used_words.add(random_word)\n",
    "        print(random_word)\n",
    "\n",
    "        # Check if the random_word is in the GloVe vocabulary\n",
    "        if glove_model.has_index_for(random_word):\n",
    "            # Call k_nearest_neighbors with the random word and use_api set to True if we haven't exceeded the API limit\n",
    "            use_api = api_calls_made < api_limit\n",
    "            print(f\"Random word: {random_word}\")\n",
    "            api_calls_made = k_nearest_neighbors(random_word, use_api=use_api)\n",
    "            print(f\"Total API calls: {api_calls_made}\")\n",
    "        else:\n",
    "            print(f\"{random_word} not in GloVe vocabulary\")\n",
    "\n",
    "        iterations += 1\n",
    "\n",
    "        # Print the count of all words in the dictionary\n",
    "        print(f\"Total words in the dictionary: {len(word_final_scores)}\")\n",
    "\n",
    "        # Save the results to the CSV file after every save_interval iterations\n",
    "        if iterations % save_interval == 0:\n",
    "            print(f\"Saving progress after {iterations} iterations\")\n",
    "            save_word_final_scores_to_csv()\n",
    "            # Write used_words to CSV file\n",
    "            with open(\"used_words.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "                csv_writer = csv.writer(csvfile)\n",
    "                csv_writer.writerow([\"Word\"])\n",
    "                for word in used_words:\n",
    "                    csv_writer.writerow([word])\n",
    "\n",
    "            # Write called_words to CSV file\n",
    "            with open(\"called_words.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "                csv_writer = csv.writer(csvfile)\n",
    "                csv_writer.writerow([\"Word\"])\n",
    "                for word in called_words:\n",
    "                    csv_writer.writerow([word])\n",
    "            \n",
    "\n",
    "        # Break the loop if you want to stop after a certain number of iterations\n",
    "        if len(used_words) >= 80000:\n",
    "            print(\"used more than 80k words\")\n",
    "            break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Call our function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_word_k_nearest_neighbors()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Saving progress\")\n",
    "save_word_final_scores_to_csv()\n",
    "\n",
    "# Print the count of all words in the dictionary\n",
    "print(f\"Total words in the dictionary: {len(word_final_scores)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes\n",
    "    - by this point we accumulated approximately 28,000 words\n",
    "        - this is up from our original list of 2,600\n",
    "        - mostly accomplished through API calls with some GloVe nearest neighbors assistance\n",
    "    - we will now create our own model with a much larger corpus of sentences\n",
    "        -we will then leverage this model to rank the remainder of our words"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Create W2V Model and Rank Remainding Words**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read used_words and called_words into csv for later reloading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write used_words to CSV file\n",
    "with open(\"used_words.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    csv_writer.writerow([\"Word\"])\n",
    "    for word in used_words:\n",
    "        csv_writer.writerow([word])\n",
    "\n",
    "# Write called_words to CSV file\n",
    "with open(\"called_words.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "    csv_writer = csv.writer(csvfile)\n",
    "    csv_writer.writerow([\"Word\"])\n",
    "    for word in called_words:\n",
    "        csv_writer.writerow([word])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write data to a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving progress\n",
      "Progress saved to word_scores.csv\n",
      "Total words in the dictionary: 107649\n"
     ]
    }
   ],
   "source": [
    "print(f\"Saving progress\")\n",
    "save_word_final_scores_to_csv()\n",
    "\n",
    "# Print the count of all words in the dictionary\n",
    "print(f\"Total words in the dictionary: {len(word_final_scores)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Word2Vec with Full Sentence Corpus"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get sentence corpus from hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/skylerestavillo/opt/anaconda3/envs/rizzlite/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Found cached dataset generics_kb (/Users/skylerestavillo/.cache/huggingface/datasets/generics_kb/generics_kb_best-13621e76244528a1/1.0.0/86da327cb38f53a3d9258e5b8ebbd7f06c766005cd6cf32e36a7f36e04cdab9c)\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.04it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "dataset = load_dataset('generics_kb', 'generics_kb_best', data_dir='/Volumes/YoMama/RizzeratorLite')\n",
    "df_unknown = pd.DataFrame(dataset['train'])\n",
    "#print('Done with df_unknown')\n",
    "#print(df_unknown.head())\n",
    "\n",
    "generic_sentences = df_unknown['generic_sentence'].tolist()\n",
    "#print('Done with generic_sentences')\n",
    "#print(generic_sentences[:5])\n",
    "df_generic = pd.DataFrame({'generic_sentence': generic_sentences})\n",
    "#print('Done with df_generic')\n",
    "#print(df_generic.head())\n",
    "\n",
    "\n",
    "\n",
    "# Define a function to preprocess each sentence\n",
    "def preprocess_sentence(sentence):\n",
    "    # Convert the input to a string and then to lowercase\n",
    "    sentence = str(sentence).lower()\n",
    "    \n",
    "    # Remove words containing numbers from the sentence\n",
    "    sentence = re.sub(r'\\b\\w*\\d\\w*\\b', '', sentence)\n",
    "    \n",
    "    # Break apart contractions using the contractions library\n",
    "    sentence = contractions.fix(sentence)\n",
    "    \n",
    "    # Remove all non-alphabetic characters from the sentence\n",
    "    sentence = re.sub(r'[^a-zA-Z\\s]', '', sentence)\n",
    "    \n",
    "    # Ensure the sentence is returned as a string of words\n",
    "    sentence = ' '.join(sentence.split())\n",
    "    \n",
    "    return sentence\n",
    "\n",
    "# Preprocess each sentence in the 'generic_sentence' column\n",
    "df_generic['generic_sentence'] = df_generic['generic_sentence'].apply(preprocess_sentence)\n",
    "\n",
    "# Print the updated dataframe\n",
    "#print(df_generic.head())\n",
    "\n",
    "# Define a function to tokenize a sentence and return a list of words\n",
    "def tokenize(sentence):\n",
    "    return sentence.split()\n",
    "\n",
    "# Update the total dictionary with all words from all sentences\n",
    "unscored_dictionary = {}\n",
    "for index, row in df_generic.iterrows():\n",
    "    sentence = row['generic_sentence']  # Access the sentence using the column name 'generic_sentence'\n",
    "    words = tokenize(sentence)\n",
    "\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            if word not in word_final_scores:\n",
    "                unscored_dictionary[word] = 0\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in the dictionary: 37524\n"
     ]
    }
   ],
   "source": [
    "# Print the count of all words in the dictionary\n",
    "print(f\"Total words in the dictionary: {len(unscored_dictionary)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get sentence corpus from eng_sentences2.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the full csv file\n",
    "df_sentence = pd.read_csv('eng_sentences2.csv', header = None)\n",
    "\n",
    "# Preprocess each sentence in the 'Sentence' column, but there is no header so use column 2\n",
    "df_sentence[2] = df_sentence[2].apply(preprocess_sentence)\n",
    "\n",
    "# Print the updated dataframe\n",
    "print(df_sentence.head())\n",
    "\n",
    "# Define a function to tokenize a sentence and return a list of words\n",
    "def tokenize(sentence):\n",
    "    return sentence.split()\n",
    "\n",
    "# Update the word_scores dictionary with words and their scores\n",
    "for index, row in df_sentence.iterrows():\n",
    "    sentence = row[2]\n",
    "    score = 0\n",
    "    words = tokenize(sentence)\n",
    "\n",
    "    for word in words:\n",
    "        if word not in stop_words:\n",
    "            if word not in word_final_scores:\n",
    "                if word not in unscored_dictionary:\n",
    "                    unscored_dictionary[word] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in the unscored dictionary: 47865\n",
      "Total words in the scored dictionary: 74566\n"
     ]
    }
   ],
   "source": [
    "# Print the count of all words in the dictionary\n",
    "print(f\"Total words in the unscored dictionary: {len(unscored_dictionary)}\")\n",
    "print(f\"Total words in the scored dictionary: {len(word_final_scores)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine sentences from both dataframes to make a Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the sentences from both dataframes\n",
    "sentences1 = df_generic['generic_sentence'].tolist()\n",
    "sentences2 = df_sentence[2].tolist()\n",
    "all_sentences = sentences1 + sentences2\n",
    "\n",
    "# Tokenize the sentences\n",
    "tokenized_sentences = [tokenize(sentence) for sentence in all_sentences]\n",
    "\n",
    "# Train a Word2Vec model using Gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec(sentences=tokenized_sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Save the Word2Vec model for future use\n",
    "model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 115038\n"
     ]
    }
   ],
   "source": [
    "# Get the vocabulary size\n",
    "vocab_size = len(model.wv.key_to_index)\n",
    "print(\"Vocabulary size:\", vocab_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Word2Vec model to process the unknown dictionary using scored words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wv_k_nearest_neighbors(random_word, k=7):\n",
    "\n",
    "    # Find k nearest neighbors (first_level_neighbors) of the input word\n",
    "    first_level_neighbors = model.wv.most_similar(random_word, topn=k)\n",
    "\n",
    "    # Separate known and unknown first_level_neighbors\n",
    "    known_first_level_neighbors = [word for word, _ in first_level_neighbors if word in word_final_scores]\n",
    "    unknown_first_level_neighbors = [word for word, _ in first_level_neighbors if word not in word_final_scores]\n",
    "\n",
    "    # Check if at least 2 of the first_level_neighbors are known\n",
    "    if len(known_first_level_neighbors) >= 2:\n",
    "        # Compute the average score of the known first_level_neighbors\n",
    "        avg_known_neighbors_score = sum(word_final_scores[word] for word in known_first_level_neighbors) / len(known_first_level_neighbors)\n",
    "\n",
    "        # Assign the average score to the input word and add it to word_final_scores\n",
    "        print(f\"Adding word: {random_word} {avg_known_neighbors_score}\")\n",
    "        word_final_scores[random_word] = avg_known_neighbors_score\n",
    "\n",
    "    # For each unknown first_level_neighbor, find their k nearest neighbors (second_level_neighbors)\n",
    "    for unknown_neighbor in unknown_first_level_neighbors:\n",
    "        second_level_neighbors = model.wv.most_similar(unknown_neighbor, topn=k)\n",
    "\n",
    "        # Calculate the average score of the known second_level_neighbors\n",
    "        known_second_level_neighbors = [word for word, _ in second_level_neighbors if word in word_final_scores]\n",
    "\n",
    "        # If there are at least 2 known second_level_neighbors, assign the average score to the unknown first_level_neighbor\n",
    "        if len(known_second_level_neighbors) >= 2:\n",
    "            avg_known_second_level_neighbors_score = sum(word_final_scores[word] for word in known_second_level_neighbors) / len(known_second_level_neighbors)\n",
    "            print(f\"Adding word: {unknown_neighbor} {avg_known_second_level_neighbors_score}\")\n",
    "            word_final_scores[unknown_neighbor] = avg_known_second_level_neighbors_score\n",
    "\n",
    "    # Recheck if there are now at least 2 known first_level_neighbors\n",
    "    known_first_level_neighbors = [word for word, _ in first_level_neighbors if word in word_final_scores]\n",
    "\n",
    "    if len(known_first_level_neighbors) >= 2:\n",
    "        # Calculate the average score of the known first_level_neighbors\n",
    "        avg_known_neighbors_score = sum(word_final_scores[word] for word in known_first_level_neighbors) / len(known_first_level_neighbors)\n",
    "\n",
    "        # Assign the average score to the input word and add it to word_final_scores\n",
    "        print(f\"Adding word: {random_word} {avg_known_neighbors_score}\")\n",
    "        word_final_scores[random_word] = avg_known_neighbors_score\n",
    "    else:\n",
    "        # Remove the input word from used_words and end the function call to try another word later\n",
    "        print(\"Removing word from used_words\")\n",
    "        used_words.remove(random_word)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def wv_random_word_k_nearest_neighbors():\n",
    "    save_interval = 500\n",
    "    iterations = 0\n",
    "\n",
    "    while True:\n",
    "        # Get the list of words found in our clean dictionary that is a non-stop word not in used_words\n",
    "        remaining_words = [word for word in unscored_dictionary.keys() if word not in stop_words and word not in used_words]\n",
    "\n",
    "        # Break the loop if there are no remaining words\n",
    "        if not remaining_words:\n",
    "            print(\"No remaining words\")\n",
    "            break\n",
    "\n",
    "        # Select a random non-stop word from the remaining_words list\n",
    "        random_word = random.choice(remaining_words)\n",
    "        used_words.add(random_word)\n",
    "        print(random_word)\n",
    "\n",
    "        # Check if the random_word is in the word2vec model vocabulary\n",
    "        if random_word in model.wv.key_to_index:\n",
    "            # Call wv_k_nearest with the random word\n",
    "            print(f\"Random word: {random_word}\")\n",
    "            wv_k_nearest_neighbors(random_word)\n",
    "        else:\n",
    "            print(f\"{random_word} not in model vocabulary\")\n",
    "\n",
    "        iterations += 1\n",
    "\n",
    "        # Print the count of all words in the dictionary\n",
    "        print(f\"Total words in the dictionary: {len(word_final_scores)}\")\n",
    "\n",
    "        # Save the results to the CSV file after every save_interval iterations\n",
    "        if iterations % save_interval == 0:\n",
    "            print(f\"Saving progress after {iterations} iterations\")\n",
    "            save_word_final_scores_to_csv()\n",
    "\n",
    "            # Write used_words to CSV file\n",
    "            with open(\"used_words.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "                csv_writer = csv.writer(csvfile)\n",
    "                csv_writer.writerow([\"Word\"])\n",
    "                for word in used_words:\n",
    "                    csv_writer.writerow([word])\n",
    "\n",
    "            # Write called_words to CSV file\n",
    "            with open(\"called_words.csv\", \"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
    "                csv_writer = csv.writer(csvfile)\n",
    "                csv_writer.writerow([\"Word\"])\n",
    "                for word in called_words:\n",
    "                    csv_writer.writerow([word])\n",
    "\n",
    "        # Break the loop if you want to stop after a certain number of iterations\n",
    "        if len(used_words) >= 130000:\n",
    "            print(\"Used more than 130k words\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_random_word_k_nearest_neighbors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Read the CSV file into df\n",
    "file_path = 'FinalDictionary.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Read score data\n",
    "scores = df['Score']\n",
    "\n",
    "# Plot the histogram\n",
    "plt.hist(scores, bins= 'auto', alpha = 0.75)\n",
    "plt.xlabel('Score')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Scores')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rizzlite",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
